{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f416eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import keras.layers\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46f795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0         0    0   18        1        0        0     4     4     0     4  ...   \n",
       "1         0    0   17        1        0        1     1     1     0     2  ...   \n",
       "2         0    0   15        1        1        1     1     1     0     2  ...   \n",
       "3         0    0   15        1        0        1     4     2     1     3  ...   \n",
       "4         0    0   16        1        0        1     3     3     2     2  ...   \n",
       "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...  ...   \n",
       "390       1    1   20        1        1        0     2     2     3     3  ...   \n",
       "391       1    1   17        1        1        1     3     1     3     3  ...   \n",
       "392       1    1   21        0        0        1     1     1     2     2  ...   \n",
       "393       1    1   18        0        1        1     3     2     3     2  ...   \n",
       "394       1    1   19        1        1        1     1     1     2     0  ...   \n",
       "\n",
       "     famrel  freetime  goout  Dalc  Walc  health  absences  G1  G2  G3  \n",
       "0         4         3      4     1     1       3         6   5   6   6  \n",
       "1         5         3      3     1     1       3         4   5   5   6  \n",
       "2         4         3      2     2     3       3        10   7   8  10  \n",
       "3         3         2      2     1     1       5         2  15  14  15  \n",
       "4         4         3      2     1     2       5         4   6  10  10  \n",
       "..      ...       ...    ...   ...   ...     ...       ...  ..  ..  ..  \n",
       "390       5         5      4     4     5       4        11   9   9   9  \n",
       "391       2         4      5     3     4       2         3  14  16  16  \n",
       "392       5         5      3     3     3       3         3  10   8   7  \n",
       "393       4         4      1     3     4       5         0  11  12  10  \n",
       "394       3         2      3     3     3       5         5   8   9   9  \n",
       "\n",
       "[395 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_excel('labelStudent.xlsx')\n",
    "del ds['Unnamed: 0']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9968e059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 18, ...,  6,  5,  6],\n",
       "       [ 0,  0, 17, ...,  4,  5,  5],\n",
       "       [ 0,  0, 15, ..., 10,  7,  8],\n",
       "       ...,\n",
       "       [ 1,  1, 21, ...,  3, 10,  8],\n",
       "       [ 1,  1, 18, ...,  0, 11, 12],\n",
       "       [ 1,  1, 19, ...,  5,  8,  9]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = ds.drop(['G3'],axis='columns')\n",
    "X = XX.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a94f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6, 10, 15, 10, 15, 11,  6, 19, 15,  9, 12, 14, 11, 16, 14, 14,\n",
       "       10,  5, 10, 15, 15, 16, 12,  8,  8, 11, 15, 11, 11, 12, 17, 16, 12,\n",
       "       15,  6, 18, 15, 11, 13, 11, 12, 18, 11,  9,  6, 11, 20, 14,  7, 13,\n",
       "       13, 10, 11, 13, 10, 15, 15,  9, 16, 11, 11,  9,  9, 10, 15, 12,  6,\n",
       "        8, 16, 15, 10,  5, 14, 11, 10, 10, 11, 10,  5, 12, 11,  6, 15, 10,\n",
       "        8,  6, 14, 10,  7,  8, 18,  6, 10, 14, 10, 15, 10, 14,  8,  5, 17,\n",
       "       14,  6, 18, 11,  8, 18, 13, 16, 19, 10, 13, 19,  9, 16, 14, 13,  8,\n",
       "       13, 15, 15, 13, 13,  8, 12, 11,  9,  0, 18,  0,  0, 12, 11,  0,  0,\n",
       "        0,  0, 12, 15,  0,  9, 11, 13,  0, 11,  0, 11,  0, 10,  0, 14, 10,\n",
       "        0, 12,  8, 13, 10, 15, 12,  0,  7,  0, 10,  7, 12, 10, 16,  0, 14,\n",
       "        0, 16, 10,  0,  9,  9, 11,  6,  9, 11,  8, 12, 17,  8, 12, 11, 11,\n",
       "       15,  9, 10, 13,  9,  8, 10, 14, 15, 16, 10, 18, 10, 16, 10, 10,  6,\n",
       "       11,  9,  7, 13, 10,  7,  8, 13, 14,  8, 10, 15,  4,  8,  8, 10,  6,\n",
       "        0, 17, 13, 14,  7, 15, 12,  9, 12, 14, 11,  9, 13,  6, 10, 13, 12,\n",
       "       11,  0, 12, 12,  0, 12,  0, 18, 13,  8,  5, 15,  8, 10,  8,  8, 12,\n",
       "        8, 13, 11, 14,  0, 18,  8, 12,  9,  0, 17, 10, 11, 10,  0,  9, 14,\n",
       "       11, 14, 10, 12,  9,  9,  8, 10,  8, 10, 12, 10, 11, 11, 19, 12, 14,\n",
       "       15, 11, 15, 13, 18, 14, 11,  0,  8, 14, 16, 11, 10, 14, 18, 13, 12,\n",
       "       18,  8, 12, 10,  0, 13, 11, 11, 13, 11,  0,  9, 10, 11, 13,  9, 11,\n",
       "       15, 15, 11, 16, 10,  9, 14,  8, 14,  0,  0,  0, 15, 13,  0, 17, 10,\n",
       "       11,  0, 15,  0, 10, 14, 16,  9, 15, 13,  8, 13,  8,  8, 11,  9, 13,\n",
       "       11, 10, 16, 13, 12, 10, 15, 12, 10, 13,  0, 10, 11,  9, 12, 11,  5,\n",
       "       19, 10, 15, 10, 15, 10, 14,  7, 10,  0,  5, 10,  6,  0,  8,  0,  9,\n",
       "       16,  7, 10,  9], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = ds['G3']\n",
    "y = yy.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6de280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (5000) in class 0 will be larger than the number of samples in the majority class (class #10 -> 56)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy={0: 5000})\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e219e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44921a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()  \n",
    "model.add(tf.keras.layers.Dense(30, activation='relu')) \n",
    "model.add(tf.keras.layers.Dense(60, activation='relu'))  \n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(30, activation='relu'))  \n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d69f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 2/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 3/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 4/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 5/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 6/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 7/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 8/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 9/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 10/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 11/300\n",
      "134/134 [==============================] - 0s 971us/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 12/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 13/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 14/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 15/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 16/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 17/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 18/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 19/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 20/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9333 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 21/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 22/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 23/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 24/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 25/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 26/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 27/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 28/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 29/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 30/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 31/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 32/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 33/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 34/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 35/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 36/300\n",
      "134/134 [==============================] - 0s 976us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 37/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 38/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 39/300\n",
      "134/134 [==============================] - 0s 945us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 40/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 41/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 42/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 43/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 44/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 45/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 46/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 47/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 48/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 49/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 50/300\n",
      "134/134 [==============================] - 0s 971us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 51/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 52/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 53/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 54/300\n",
      "134/134 [==============================] - 0s 978us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 56/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 57/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 58/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 59/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 60/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 61/300\n",
      "134/134 [==============================] - 0s 980us/step - loss: 0.0000e+00 - accuracy: 0.9342 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 62/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 63/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 64/300\n",
      "134/134 [==============================] - 0s 940us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 65/300\n",
      "134/134 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 66/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 67/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 68/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 69/300\n",
      "134/134 [==============================] - 0s 964us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 70/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 71/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 72/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9342 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 73/300\n",
      "134/134 [==============================] - 0s 961us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 74/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 75/300\n",
      "134/134 [==============================] - 0s 963us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 76/300\n",
      "134/134 [==============================] - 0s 954us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 77/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 78/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 79/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 80/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 81/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 82/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 83/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 84/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 85/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 86/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 87/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 88/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9344 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 89/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 90/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 91/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 92/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 93/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 94/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 95/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 96/300\n",
      "134/134 [==============================] - 0s 975us/step - loss: 0.0000e+00 - accuracy: 0.9340 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 97/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 98/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 99/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 100/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 101/300\n",
      "134/134 [==============================] - 0s 999us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 102/300\n",
      "134/134 [==============================] - 0s 961us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 103/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 104/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 105/300\n",
      "134/134 [==============================] - 0s 959us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 106/300\n",
      "134/134 [==============================] - 0s 960us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 107/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 108/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 109/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 110/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 111/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 112/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 113/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 114/300\n",
      "134/134 [==============================] - 0s 947us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 115/300\n",
      "134/134 [==============================] - 0s 951us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 116/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 117/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 118/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 119/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 120/300\n",
      "134/134 [==============================] - 0s 964us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 121/300\n",
      "134/134 [==============================] - 0s 963us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 122/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 123/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 124/300\n",
      "134/134 [==============================] - 0s 947us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 125/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 126/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 127/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 128/300\n",
      "134/134 [==============================] - 0s 953us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 129/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 130/300\n",
      "134/134 [==============================] - 0s 947us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 131/300\n",
      "134/134 [==============================] - 0s 986us/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 132/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 133/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 134/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9340 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 135/300\n",
      "134/134 [==============================] - 0s 994us/step - loss: 0.0000e+00 - accuracy: 0.9342 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 136/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 137/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 138/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 139/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 140/300\n",
      "134/134 [==============================] - 0s 978us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 141/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 142/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 143/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 144/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 145/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 146/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 147/300\n",
      "134/134 [==============================] - 0s 965us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 148/300\n",
      "134/134 [==============================] - 0s 973us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 149/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 150/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 151/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 152/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 153/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 154/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 155/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 156/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 157/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 158/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 159/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 160/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9342 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 972us/step - loss: 0.0000e+00 - accuracy: 0.9307 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 162/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 163/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 164/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9344 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 165/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 166/300\n",
      "134/134 [==============================] - 0s 946us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 167/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 168/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 169/300\n",
      "134/134 [==============================] - 0s 966us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 170/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 171/300\n",
      "134/134 [==============================] - 0s 965us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 172/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 173/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 174/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 175/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 176/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9344 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 177/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 178/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 179/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 180/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 181/300\n",
      "134/134 [==============================] - 0s 971us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 182/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 183/300\n",
      "134/134 [==============================] - 0s 955us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 184/300\n",
      "134/134 [==============================] - 0s 971us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 185/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 186/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 187/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 188/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 189/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 190/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 191/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 192/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 193/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 194/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 195/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 196/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 197/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 198/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 199/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 200/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 201/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 202/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 203/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 204/300\n",
      "134/134 [==============================] - 0s 979us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 205/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 206/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 207/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 208/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 209/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 210/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 211/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 212/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 213/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 215/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 216/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 217/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 218/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 219/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 220/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9226\n",
      "Epoch 221/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 222/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 223/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 224/300\n",
      "134/134 [==============================] - 0s 972us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 225/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 226/300\n",
      "134/134 [==============================] - 0s 960us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 227/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 228/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9347 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 229/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 230/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 231/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 232/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 233/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 234/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 235/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9326 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 236/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 237/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 238/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 239/300\n",
      "134/134 [==============================] - 0s 985us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 240/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 241/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 242/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 243/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 244/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 245/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9344 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 246/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 247/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 248/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 249/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 250/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 251/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 252/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 253/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 254/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 255/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9333 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 256/300\n",
      "134/134 [==============================] - 0s 975us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 257/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 258/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 259/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 260/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 261/300\n",
      "134/134 [==============================] - 0s 967us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 262/300\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 263/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 264/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 265/300\n",
      "134/134 [==============================] - 0s 984us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 266/300\n",
      "134/134 [==============================] - 0s 959us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 267/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 268/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 269/300\n",
      "134/134 [==============================] - 0s 969us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 270/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 271/300\n",
      "134/134 [==============================] - 0s 992us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 272/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 273/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 274/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 275/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 276/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9319 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 277/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 278/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 279/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 280/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 281/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 282/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 283/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 284/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 285/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9349 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 286/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 287/300\n",
      "134/134 [==============================] - 0s 1000us/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 288/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 289/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 290/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 291/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 292/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 293/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 294/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 295/300\n",
      "134/134 [==============================] - 0s 977us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 296/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9351 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 297/300\n",
      "134/134 [==============================] - 0s 970us/step - loss: 0.0000e+00 - accuracy: 0.9356 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 298/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9333 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 299/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9354 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n",
      "Epoch 300/300\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.9358 - val_loss: 0.0000e+00 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=300, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137aac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(history.history['accuracy'], history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93ebe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      4010\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         6\n",
      "         6.0       0.00      0.00      0.00        12\n",
      "         7.0       0.00      0.00      0.00         6\n",
      "         8.0       0.00      0.00      0.00        20\n",
      "         9.0       0.00      0.00      0.00        24\n",
      "        10.0       0.00      0.00      0.00        46\n",
      "        11.0       0.00      0.00      0.00        38\n",
      "        12.0       0.00      0.00      0.00        24\n",
      "        13.0       0.00      0.00      0.00        21\n",
      "        14.0       0.00      0.00      0.00        20\n",
      "        15.0       0.00      0.00      0.00        29\n",
      "        16.0       0.00      0.00      0.00        11\n",
      "        17.0       0.00      0.00      0.00         5\n",
      "        18.0       0.00      0.00      0.00         8\n",
      "        19.0       0.00      0.00      0.00         3\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94      4285\n",
      "   macro avg       0.05      0.05      0.05      4285\n",
      "weighted avg       0.94      0.94      0.94      4285\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\OAK\\anaconda3\\envs\\DMenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"NN\")\n",
    "print(metrics.classification_report(y_train, model.predict(X_train))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
